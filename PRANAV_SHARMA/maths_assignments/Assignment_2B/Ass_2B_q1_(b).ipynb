{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0592a8d7",
   "metadata": {},
   "source": [
    "# Question 1 :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3968fa",
   "metadata": {},
   "source": [
    "## Part (a) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3285b",
   "metadata": {},
   "source": [
    "It provides information about central tendency measure of distribution of y given x and helps in predicting y for any given new value of x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70c7dd",
   "metadata": {},
   "source": [
    "## Part (b) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06346986",
   "metadata": {},
   "source": [
    "## Dataset generation with normally distributed dependent variable :\n",
    "\n",
    "$In\\ linear\\ regression\\ we\\ are\\ using\\ the\\ assumption\\ that\\ the\\ noise\\ \\epsilon \\ is\\ following\\ N(0,\\sigma^2)$<br>\n",
    "$y=X.\\beta+\\epsilon \\ and\\ f(\\epsilon)\\sim N(0,\\sigma^2)$<br>\n",
    "$\\therefore we \\ can\\ say\\ y\\sim N(X.\\beta,\\sigma^2)$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffe1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2        x3        x4        x5          y\n",
      "0  0.374540  0.950714  0.731994  0.598658  0.156019  12.030134\n",
      "1  0.155995  0.058084  0.866176  0.601115  0.708073  14.084078\n",
      "2  0.020584  0.969910  0.832443  0.212339  0.181825  12.015695\n",
      "3  0.183405  0.304242  0.524756  0.431945  0.291229   8.349480\n",
      "4  0.611853  0.139494  0.292145  0.366362  0.456070   9.908686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "np.random.seed(42)\n",
    "num_samples= n = 150\n",
    "num_features = 5\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "coefficients = np.array([6, 3, 9 ,2 , 4])\n",
    "error = np.random.normal(0, 1, num_samples)\n",
    "y = np.dot(X, coefficients) + error\n",
    "data = pd.DataFrame(np.column_stack((X, y)), columns=['x1', 'x2', 'x3', 'x4', 'x5', 'y'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5e6b4",
   "metadata": {},
   "source": [
    "## Optimization :\n",
    "\n",
    "$f(y|x;\\beta,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{\\frac{-(y-\\mu)^2}{2\\sigma^2}}$<br>\n",
    "$L_x(\\beta,\\sigma^2)=\\prod_{i}^{n} f(y|x)$<br>\n",
    "$\\log (L_x(\\beta,\\sigma^2))=\\sum_{i}^{n}(-\\log(2\\pi \\sigma^2) \\ - \\  \\frac{(y-X.\\beta)^2}{2\\sigma^2})$<br>\n",
    "$we\\ will\\ maximize\\ the\\ likelihood\\ function\\ by\\ minimizing\\ -log \\ likelihood\\ ,\\ we\\ will\\ use\\ scipy.opitimize\\ for\\ it$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac81bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient_ 0 = 5.866810144946875\n",
      "Coefficient_ 1 = 2.6602119103479067\n",
      "Coefficient_ 2 = 9.356896716572587\n",
      "Coefficient_ 3 = 2.2388260822091377\n",
      "Coefficient_ 4 = 3.917942351138697\n",
      "Variance= 1.002076435009208\n"
     ]
    }
   ],
   "source": [
    "def negative_log_likelihood(params, X, y):\n",
    "    mean = np.dot(X, params[:-1])\n",
    "    std = params[-1]\n",
    "    log_likelihood = np.sum(-np.log(np.sqrt(2 * np.pi * std**2)) - (y - mean) ** 2 / (2 * std**2))\n",
    "    return -log_likelihood\n",
    "\n",
    "# use any value for initial parameters\n",
    "initial_params = np.array([1, 2, 3, 4, 5, 1])\n",
    "\n",
    "result = minimize(negative_log_likelihood, initial_params, args=(X, y))\n",
    "\n",
    "for i in range(num_features):\n",
    "    print(\"Coefficient_\",i,\"=\",result.x[i])\n",
    "print(\"Variance=\",result.x[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922d4fc",
   "metadata": {},
   "source": [
    "## Choice of sigma :\n",
    "As we increase the value of sigma the estimated coefficient error increases and the prediction becomes poor.<br>\n",
    "\n",
    "But parametrizing variance has no effect on the predicted values of coefficients as when we equate the derivative of likelihood function to zero the variance term becomes zero and has no role to play in the value of the predicted coefficients as we can see below that fixing the value of std doesn't change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd21fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient_ 0 = 5.866810118881706\n",
      "Coefficient_ 1 = 2.6602119066641556\n",
      "Coefficient_ 2 = 9.35689663192498\n",
      "Coefficient_ 3 = 2.238825776433035\n",
      "Coefficient_ 4 = 3.917942752355967\n"
     ]
    }
   ],
   "source": [
    "def negative_log_likelihood(params, X, y):\n",
    "    mean = np.dot(X, params)\n",
    "    std = 1\n",
    "    log_likelihood = np.sum(-np.log(np.sqrt(2 * np.pi * std**2)) - (y - mean) ** 2 / (2 * std**2))\n",
    "    return -log_likelihood\n",
    "\n",
    "# use any value for initial parameters\n",
    "initial_params = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "result = minimize(negative_log_likelihood, initial_params, args=(X, y))\n",
    "\n",
    "for i in range(num_features):\n",
    "    print(\"Coefficient_\",i,\"=\",result.x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fe087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
