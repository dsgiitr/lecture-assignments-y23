{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NOZaiyCArZN",
        "outputId": "f8daafbc-8e5c-4156-be27-f9ef465e733d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(s):\n",
        "  data=pd.read_csv(s)\n",
        "  return data\n",
        "\n",
        "path_a1raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/a1_raw.csv'\n",
        "path_a2raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/a2_raw.csv'\n",
        "path_a3raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/a3_raw.csv'\n",
        "path_b1raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/b1_raw.csv'\n",
        "path_b3raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/b3_raw.csv'\n",
        "path_c1raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/c1_raw.csv'\n",
        "path_c3raw='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/c3_raw.csv'\n",
        "\n",
        "path_a1='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/a1_va3.csv'\n",
        "path_a3='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/a3_va3.csv'\n",
        "path_test='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/test.csv'\n",
        "path_b1='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/b1_va3.csv'\n",
        "path_b3='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/b3_va3.csv'\n",
        "path_c1='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/c1_va3.csv'\n",
        "path_c3='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/c3_va3.csv'\n",
        "path_test='/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/test.csv'\n",
        "\n",
        "data_a1=load_data(path_a1)\n",
        "data_a3=load_data(path_a3)\n",
        "data_b1=load_data(path_b1)\n",
        "data_b3=load_data(path_b3)\n",
        "data_c1=load_data(path_c1)\n",
        "data_c3=load_data(path_c3)\n",
        "data_a1raw=load_data(path_a1raw)\n",
        "data_a2raw=load_data(path_a2raw)\n",
        "data_a3raw=load_data(path_a3raw)\n",
        "data_b1raw=load_data(path_b1raw)\n",
        "data_b3raw=load_data(path_b3raw)\n",
        "data_c1raw=load_data(path_c1raw)\n",
        "data_c3raw=load_data(path_c3raw)\n",
        "test=load_data(path_test)\n"
      ],
      "metadata": {
        "id": "3oOZi4n0YtyQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_a1raw['phase'].unique())\n",
        "print(data_a2raw['phase'].unique())\n",
        "print(data_a3raw['phase'].unique())\n",
        "print(data_b1raw['phase'].unique())\n",
        "print(data_b3raw['phase'].unique())\n",
        "print(data_c1raw['phase'].unique())\n",
        "print(data_c3raw['phase'].unique())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwsMc--NV7nr",
        "outputId": "64bc90ef-367a-491f-bc18-0fa5680da663"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rest' 'Preparation' 'Stroke' 'Hold' 'Retraction']\n",
            "['Rest' 'Preparation' 'Stroke' 'Retraction' 'Hold']\n",
            "['Rest' 'Preparation' 'Stroke' 'Retraction' 'Hold']\n",
            "['Rest' 'Preparation' 'Hold' 'Stroke' 'Retraction' 'Preparação']\n",
            "['Rest' 'Preparation' 'Hold' 'Stroke' 'Retraction']\n",
            "['Rest' 'Preparation' 'Stroke' 'Hold' 'Retraction']\n",
            "['Rest' 'Preparation' 'Stroke' 'Hold' 'Retraction']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_b1raw['phase']=data_b1raw['phase'].replace(['Preparação'],['Preparation'])\n",
        "data_b1raw['phase'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wXLPeIeYoF2",
        "outputId": "8085c572-51a8-42eb-da6e-3e723b132527"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Rest', 'Preparation', 'Hold', 'Stroke', 'Retraction'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "framesprocessed=[data_a1,data_a3,data_b1,data_b3,data_c1,data_c3]\n",
        "framesraw=[data_a1raw,data_a3raw,data_b1raw,data_b3raw,data_c1raw,data_c3raw]\n",
        "\n",
        "for i in framesraw:\n",
        "  i.drop(range(0,4),inplace=True)\n",
        "  i.reset_index()\n",
        "\n",
        "final=pd.concat(framesraw)\n",
        "final.reset_index(inplace=True)\n",
        "finalv=pd.concat(framesprocessed)\n",
        "finalv.reset_index(inplace=True)\n",
        "final_df=pd.concat([finalv,final],axis=1)\n",
        "final_df"
      ],
      "metadata": {
        "id": "0hnNF188SYzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1c43b604-b0de-424c-b509-7facd10b885c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index         1         2         3         4         5         6  \\\n",
              "0         0 -0.005009 -0.000964  0.000573  0.008623  0.005667  0.001302   \n",
              "1         1  0.004905  0.001209 -0.000649  0.004737  0.003166  0.000819   \n",
              "2         2 -0.002393 -0.000216  0.000136  0.003028  0.001212  0.000336   \n",
              "3         3 -0.001394 -0.000242  0.000056  0.001182  0.000575  0.000225   \n",
              "4         4 -0.000156 -0.000004  0.000023  0.001585  0.000630  0.000094   \n",
              "...     ...       ...       ...       ...       ...       ...       ...   \n",
              "8608   1439 -0.003709 -0.006168  0.000786 -0.000155  0.001088 -0.000144   \n",
              "8609   1440 -0.000727  0.001536 -0.000211  0.000700 -0.000975  0.000067   \n",
              "8610   1441  0.003074  0.007870 -0.000962  0.000526 -0.000779  0.000090   \n",
              "8611   1442  0.003297  0.008467 -0.001035  0.000578 -0.000740  0.000101   \n",
              "8612   1443  0.000204 -0.000040  0.000058  0.000586 -0.000619  0.000087   \n",
              "\n",
              "             7         8         9  ...        sy        sz       lwx  \\\n",
              "0    -0.000631  0.000130 -0.000048  ...  4.225485  1.775536  4.983912   \n",
              "1    -0.000572 -0.000015  0.000023  ...  4.223284  1.777401  5.000410   \n",
              "2    -0.000449  0.000017  0.000047  ...  4.223690  1.777571  5.001656   \n",
              "3    -0.000479 -0.000050  0.000104  ...  4.224827  1.777669  5.002672   \n",
              "4    -0.000303  0.000097  0.000065  ...  4.223671  1.778054  5.012298   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "8608 -0.003815 -0.004658  0.000656  ...  4.199645  1.939572  3.801623   \n",
              "8609 -0.001147  0.000177  0.000008  ...  4.199096  1.939843  3.736713   \n",
              "8610  0.002786  0.005035 -0.000606  ...  4.200613  1.940351  3.736855   \n",
              "8611  0.002947  0.005385 -0.000652  ...  4.200203  1.940679  3.736708   \n",
              "8612  0.000229  0.000003  0.000061  ...  4.198929  1.941195  3.736303   \n",
              "\n",
              "           lwy       lwz       rwx       rwy       rwz  timestamp  phase  \n",
              "0     4.296833  1.569889  5.193762  4.335417  1.560144    5702167   Rest  \n",
              "1     4.301358  1.566544  5.164159  4.313107  1.552097    5702307   Rest  \n",
              "2     4.299812  1.566537  5.136817  4.307087  1.551576    5702338   Rest  \n",
              "3     4.298810  1.566489  5.125220  4.300282  1.550805    5702370   Rest  \n",
              "4     4.298582  1.565061  5.114789  4.292008  1.549765    5702432   Rest  \n",
              "...        ...       ...       ...       ...       ...        ...    ...  \n",
              "8608  5.192412  1.812156  5.206748  5.086565  1.837070    5432739   Rest  \n",
              "8609  5.067120  1.828599  5.205452  5.085346  1.837165    5432771   Rest  \n",
              "8610  5.068608  1.828367  5.202618  5.090534  1.836787    5432808   Rest  \n",
              "8611  5.067500  1.828450  5.196628  5.095811  1.836236    5432836   Rest  \n",
              "8612  5.066618  1.828540  5.194844  5.096206  1.836543    5432869   Rest  \n",
              "\n",
              "[8613 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38a12cb1-e277-46b1-a0de-2422d5dfe31c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>sy</th>\n",
              "      <th>sz</th>\n",
              "      <th>lwx</th>\n",
              "      <th>lwy</th>\n",
              "      <th>lwz</th>\n",
              "      <th>rwx</th>\n",
              "      <th>rwy</th>\n",
              "      <th>rwz</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.005009</td>\n",
              "      <td>-0.000964</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.008623</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>0.001302</td>\n",
              "      <td>-0.000631</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>...</td>\n",
              "      <td>4.225485</td>\n",
              "      <td>1.775536</td>\n",
              "      <td>4.983912</td>\n",
              "      <td>4.296833</td>\n",
              "      <td>1.569889</td>\n",
              "      <td>5.193762</td>\n",
              "      <td>4.335417</td>\n",
              "      <td>1.560144</td>\n",
              "      <td>5702167</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.004905</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>-0.000649</td>\n",
              "      <td>0.004737</td>\n",
              "      <td>0.003166</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>...</td>\n",
              "      <td>4.223284</td>\n",
              "      <td>1.777401</td>\n",
              "      <td>5.000410</td>\n",
              "      <td>4.301358</td>\n",
              "      <td>1.566544</td>\n",
              "      <td>5.164159</td>\n",
              "      <td>4.313107</td>\n",
              "      <td>1.552097</td>\n",
              "      <td>5702307</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.002393</td>\n",
              "      <td>-0.000216</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.003028</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>-0.000449</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>...</td>\n",
              "      <td>4.223690</td>\n",
              "      <td>1.777571</td>\n",
              "      <td>5.001656</td>\n",
              "      <td>4.299812</td>\n",
              "      <td>1.566537</td>\n",
              "      <td>5.136817</td>\n",
              "      <td>4.307087</td>\n",
              "      <td>1.551576</td>\n",
              "      <td>5702338</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.001394</td>\n",
              "      <td>-0.000242</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.001182</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>-0.000479</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>...</td>\n",
              "      <td>4.224827</td>\n",
              "      <td>1.777669</td>\n",
              "      <td>5.002672</td>\n",
              "      <td>4.298810</td>\n",
              "      <td>1.566489</td>\n",
              "      <td>5.125220</td>\n",
              "      <td>4.300282</td>\n",
              "      <td>1.550805</td>\n",
              "      <td>5702370</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.000156</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>-0.000303</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>...</td>\n",
              "      <td>4.223671</td>\n",
              "      <td>1.778054</td>\n",
              "      <td>5.012298</td>\n",
              "      <td>4.298582</td>\n",
              "      <td>1.565061</td>\n",
              "      <td>5.114789</td>\n",
              "      <td>4.292008</td>\n",
              "      <td>1.549765</td>\n",
              "      <td>5702432</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8608</th>\n",
              "      <td>1439</td>\n",
              "      <td>-0.003709</td>\n",
              "      <td>-0.006168</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>-0.000155</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>-0.000144</td>\n",
              "      <td>-0.003815</td>\n",
              "      <td>-0.004658</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>...</td>\n",
              "      <td>4.199645</td>\n",
              "      <td>1.939572</td>\n",
              "      <td>3.801623</td>\n",
              "      <td>5.192412</td>\n",
              "      <td>1.812156</td>\n",
              "      <td>5.206748</td>\n",
              "      <td>5.086565</td>\n",
              "      <td>1.837070</td>\n",
              "      <td>5432739</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8609</th>\n",
              "      <td>1440</td>\n",
              "      <td>-0.000727</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>-0.000975</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>...</td>\n",
              "      <td>4.199096</td>\n",
              "      <td>1.939843</td>\n",
              "      <td>3.736713</td>\n",
              "      <td>5.067120</td>\n",
              "      <td>1.828599</td>\n",
              "      <td>5.205452</td>\n",
              "      <td>5.085346</td>\n",
              "      <td>1.837165</td>\n",
              "      <td>5432771</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8610</th>\n",
              "      <td>1441</td>\n",
              "      <td>0.003074</td>\n",
              "      <td>0.007870</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.002786</td>\n",
              "      <td>0.005035</td>\n",
              "      <td>-0.000606</td>\n",
              "      <td>...</td>\n",
              "      <td>4.200613</td>\n",
              "      <td>1.940351</td>\n",
              "      <td>3.736855</td>\n",
              "      <td>5.068608</td>\n",
              "      <td>1.828367</td>\n",
              "      <td>5.202618</td>\n",
              "      <td>5.090534</td>\n",
              "      <td>1.836787</td>\n",
              "      <td>5432808</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8611</th>\n",
              "      <td>1442</td>\n",
              "      <td>0.003297</td>\n",
              "      <td>0.008467</td>\n",
              "      <td>-0.001035</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>0.005385</td>\n",
              "      <td>-0.000652</td>\n",
              "      <td>...</td>\n",
              "      <td>4.200203</td>\n",
              "      <td>1.940679</td>\n",
              "      <td>3.736708</td>\n",
              "      <td>5.067500</td>\n",
              "      <td>1.828450</td>\n",
              "      <td>5.196628</td>\n",
              "      <td>5.095811</td>\n",
              "      <td>1.836236</td>\n",
              "      <td>5432836</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8612</th>\n",
              "      <td>1443</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000586</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>...</td>\n",
              "      <td>4.198929</td>\n",
              "      <td>1.941195</td>\n",
              "      <td>3.736303</td>\n",
              "      <td>5.066618</td>\n",
              "      <td>1.828540</td>\n",
              "      <td>5.194844</td>\n",
              "      <td>5.096206</td>\n",
              "      <td>1.836543</td>\n",
              "      <td>5432869</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8613 rows × 55 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38a12cb1-e277-46b1-a0de-2422d5dfe31c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38a12cb1-e277-46b1-a0de-2422d5dfe31c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38a12cb1-e277-46b1-a0de-2422d5dfe31c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ace90b6a-98e4-436d-9f0d-0f7c2c1e8edc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ace90b6a-98e4-436d-9f0d-0f7c2c1e8edc')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ace90b6a-98e4-436d-9f0d-0f7c2c1e8edc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.drop(['Phase'],axis=1,inplace=True)\n",
        "list1=list(range(0,5))\n",
        "print(final_df['phase'].unique())\n",
        "final_df['phase'].replace(final_df['phase'].unique(),list1,inplace=True)"
      ],
      "metadata": {
        "id": "lAQuSOMcXhZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40de825-89bb-45e5-cc5b-8cf8246325b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rest' 'Preparation' 'Stroke' 'Hold' 'Retraction']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y=final_df['phase'].values\n",
        "final_df['phase'].unique()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmFlaaLBcGSW",
        "outputId": "eed7aec0-4d15-4e77-b849-f49823461ba4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=final_df.drop(['phase'],axis=1)"
      ],
      "metadata": {
        "id": "cLrh-HwpZQw2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.drop(['index'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "O8glM7I1YIQb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm\n",
        "\n",
        "lgbm=lgbm.LGBMClassifier()\n",
        "\n",
        "X"
      ],
      "metadata": {
        "id": "zf3ja_z4ZzGS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "ee4f18e3-958e-4db5-c9e1-952088693cef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             1         2         3         4         5         6         7  \\\n",
              "0    -0.005009 -0.000964  0.000573  0.008623  0.005667  0.001302 -0.000631   \n",
              "1     0.004905  0.001209 -0.000649  0.004737  0.003166  0.000819 -0.000572   \n",
              "2    -0.002393 -0.000216  0.000136  0.003028  0.001212  0.000336 -0.000449   \n",
              "3    -0.001394 -0.000242  0.000056  0.001182  0.000575  0.000225 -0.000479   \n",
              "4    -0.000156 -0.000004  0.000023  0.001585  0.000630  0.000094 -0.000303   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "8608 -0.003709 -0.006168  0.000786 -0.000155  0.001088 -0.000144 -0.003815   \n",
              "8609 -0.000727  0.001536 -0.000211  0.000700 -0.000975  0.000067 -0.001147   \n",
              "8610  0.003074  0.007870 -0.000962  0.000526 -0.000779  0.000090  0.002786   \n",
              "8611  0.003297  0.008467 -0.001035  0.000578 -0.000740  0.000101  0.002947   \n",
              "8612  0.000204 -0.000040  0.000058  0.000586 -0.000619  0.000087  0.000229   \n",
              "\n",
              "             8         9        10  ...        sx        sy        sz  \\\n",
              "0     0.000130 -0.000048  0.007762  ...  5.052367  4.225485  1.775536   \n",
              "1    -0.000015  0.000023  0.002706  ...  5.045395  4.223284  1.777401   \n",
              "2     0.000017  0.000047  0.002868  ...  5.045374  4.223690  1.777571   \n",
              "3    -0.000050  0.000104  0.001171  ...  5.045767  4.224827  1.777669   \n",
              "4     0.000097  0.000065  0.001579  ...  5.047422  4.223671  1.778054   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "8608 -0.004658  0.000656  0.000060  ...  4.473687  4.199645  1.939572   \n",
              "8609  0.000177  0.000008  0.000423  ...  4.474245  4.199096  1.939843   \n",
              "8610  0.005035 -0.000606  0.000413  ...  4.476590  4.200613  1.940351   \n",
              "8611  0.005385 -0.000652  0.000580  ...  4.477201  4.200203  1.940679   \n",
              "8612  0.000003  0.000061  0.000644  ...  4.478990  4.198929  1.941195   \n",
              "\n",
              "           lwx       lwy       lwz       rwx       rwy       rwz  timestamp  \n",
              "0     4.983912  4.296833  1.569889  5.193762  4.335417  1.560144    5702167  \n",
              "1     5.000410  4.301358  1.566544  5.164159  4.313107  1.552097    5702307  \n",
              "2     5.001656  4.299812  1.566537  5.136817  4.307087  1.551576    5702338  \n",
              "3     5.002672  4.298810  1.566489  5.125220  4.300282  1.550805    5702370  \n",
              "4     5.012298  4.298582  1.565061  5.114789  4.292008  1.549765    5702432  \n",
              "...        ...       ...       ...       ...       ...       ...        ...  \n",
              "8608  3.801623  5.192412  1.812156  5.206748  5.086565  1.837070    5432739  \n",
              "8609  3.736713  5.067120  1.828599  5.205452  5.085346  1.837165    5432771  \n",
              "8610  3.736855  5.068608  1.828367  5.202618  5.090534  1.836787    5432808  \n",
              "8611  3.736708  5.067500  1.828450  5.196628  5.095811  1.836236    5432836  \n",
              "8612  3.736303  5.066618  1.828540  5.194844  5.096206  1.836543    5432869  \n",
              "\n",
              "[8613 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2c11135-20bd-4075-be74-a2890450cd28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>sx</th>\n",
              "      <th>sy</th>\n",
              "      <th>sz</th>\n",
              "      <th>lwx</th>\n",
              "      <th>lwy</th>\n",
              "      <th>lwz</th>\n",
              "      <th>rwx</th>\n",
              "      <th>rwy</th>\n",
              "      <th>rwz</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.005009</td>\n",
              "      <td>-0.000964</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>0.008623</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>0.001302</td>\n",
              "      <td>-0.000631</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>0.007762</td>\n",
              "      <td>...</td>\n",
              "      <td>5.052367</td>\n",
              "      <td>4.225485</td>\n",
              "      <td>1.775536</td>\n",
              "      <td>4.983912</td>\n",
              "      <td>4.296833</td>\n",
              "      <td>1.569889</td>\n",
              "      <td>5.193762</td>\n",
              "      <td>4.335417</td>\n",
              "      <td>1.560144</td>\n",
              "      <td>5702167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004905</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>-0.000649</td>\n",
              "      <td>0.004737</td>\n",
              "      <td>0.003166</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.002706</td>\n",
              "      <td>...</td>\n",
              "      <td>5.045395</td>\n",
              "      <td>4.223284</td>\n",
              "      <td>1.777401</td>\n",
              "      <td>5.000410</td>\n",
              "      <td>4.301358</td>\n",
              "      <td>1.566544</td>\n",
              "      <td>5.164159</td>\n",
              "      <td>4.313107</td>\n",
              "      <td>1.552097</td>\n",
              "      <td>5702307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.002393</td>\n",
              "      <td>-0.000216</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.003028</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>0.000336</td>\n",
              "      <td>-0.000449</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.002868</td>\n",
              "      <td>...</td>\n",
              "      <td>5.045374</td>\n",
              "      <td>4.223690</td>\n",
              "      <td>1.777571</td>\n",
              "      <td>5.001656</td>\n",
              "      <td>4.299812</td>\n",
              "      <td>1.566537</td>\n",
              "      <td>5.136817</td>\n",
              "      <td>4.307087</td>\n",
              "      <td>1.551576</td>\n",
              "      <td>5702338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.001394</td>\n",
              "      <td>-0.000242</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.001182</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>-0.000479</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.001171</td>\n",
              "      <td>...</td>\n",
              "      <td>5.045767</td>\n",
              "      <td>4.224827</td>\n",
              "      <td>1.777669</td>\n",
              "      <td>5.002672</td>\n",
              "      <td>4.298810</td>\n",
              "      <td>1.566489</td>\n",
              "      <td>5.125220</td>\n",
              "      <td>4.300282</td>\n",
              "      <td>1.550805</td>\n",
              "      <td>5702370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.000156</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>-0.000303</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>...</td>\n",
              "      <td>5.047422</td>\n",
              "      <td>4.223671</td>\n",
              "      <td>1.778054</td>\n",
              "      <td>5.012298</td>\n",
              "      <td>4.298582</td>\n",
              "      <td>1.565061</td>\n",
              "      <td>5.114789</td>\n",
              "      <td>4.292008</td>\n",
              "      <td>1.549765</td>\n",
              "      <td>5702432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8608</th>\n",
              "      <td>-0.003709</td>\n",
              "      <td>-0.006168</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>-0.000155</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>-0.000144</td>\n",
              "      <td>-0.003815</td>\n",
              "      <td>-0.004658</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>...</td>\n",
              "      <td>4.473687</td>\n",
              "      <td>4.199645</td>\n",
              "      <td>1.939572</td>\n",
              "      <td>3.801623</td>\n",
              "      <td>5.192412</td>\n",
              "      <td>1.812156</td>\n",
              "      <td>5.206748</td>\n",
              "      <td>5.086565</td>\n",
              "      <td>1.837070</td>\n",
              "      <td>5432739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8609</th>\n",
              "      <td>-0.000727</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>-0.000975</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>...</td>\n",
              "      <td>4.474245</td>\n",
              "      <td>4.199096</td>\n",
              "      <td>1.939843</td>\n",
              "      <td>3.736713</td>\n",
              "      <td>5.067120</td>\n",
              "      <td>1.828599</td>\n",
              "      <td>5.205452</td>\n",
              "      <td>5.085346</td>\n",
              "      <td>1.837165</td>\n",
              "      <td>5432771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8610</th>\n",
              "      <td>0.003074</td>\n",
              "      <td>0.007870</td>\n",
              "      <td>-0.000962</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.002786</td>\n",
              "      <td>0.005035</td>\n",
              "      <td>-0.000606</td>\n",
              "      <td>0.000413</td>\n",
              "      <td>...</td>\n",
              "      <td>4.476590</td>\n",
              "      <td>4.200613</td>\n",
              "      <td>1.940351</td>\n",
              "      <td>3.736855</td>\n",
              "      <td>5.068608</td>\n",
              "      <td>1.828367</td>\n",
              "      <td>5.202618</td>\n",
              "      <td>5.090534</td>\n",
              "      <td>1.836787</td>\n",
              "      <td>5432808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8611</th>\n",
              "      <td>0.003297</td>\n",
              "      <td>0.008467</td>\n",
              "      <td>-0.001035</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>-0.000740</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>0.005385</td>\n",
              "      <td>-0.000652</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>...</td>\n",
              "      <td>4.477201</td>\n",
              "      <td>4.200203</td>\n",
              "      <td>1.940679</td>\n",
              "      <td>3.736708</td>\n",
              "      <td>5.067500</td>\n",
              "      <td>1.828450</td>\n",
              "      <td>5.196628</td>\n",
              "      <td>5.095811</td>\n",
              "      <td>1.836236</td>\n",
              "      <td>5432836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8612</th>\n",
              "      <td>0.000204</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000586</td>\n",
              "      <td>-0.000619</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>...</td>\n",
              "      <td>4.478990</td>\n",
              "      <td>4.198929</td>\n",
              "      <td>1.941195</td>\n",
              "      <td>3.736303</td>\n",
              "      <td>5.066618</td>\n",
              "      <td>1.828540</td>\n",
              "      <td>5.194844</td>\n",
              "      <td>5.096206</td>\n",
              "      <td>1.836543</td>\n",
              "      <td>5432869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8613 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2c11135-20bd-4075-be74-a2890450cd28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2c11135-20bd-4075-be74-a2890450cd28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2c11135-20bd-4075-be74-a2890450cd28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a7844e4-24ec-4b9d-94b2-ea799cc742f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a7844e4-24ec-4b9d-94b2-ea799cc742f8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a7844e4-24ec-4b9d-94b2-ea799cc742f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otA0Zm92fw0h",
        "outputId": "b9c83261-686b-41a2-af8a-ebf22cc3f986"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm.fit(X,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "aqDhvd1g4b-z",
        "outputId": "eba62194-ea74-4a98-bbee-f7531a491e02"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 13005\n",
            "[LightGBM] [Info] Number of data points in the train set: 8613, number of used features: 51\n",
            "[LightGBM] [Info] Start training from score -1.341454\n",
            "[LightGBM] [Info] Start training from score -1.512999\n",
            "[LightGBM] [Info] Start training from score -1.229411\n",
            "[LightGBM] [Info] Start training from score -2.210902\n",
            "[LightGBM] [Info] Start training from score -2.152273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_a2=data_a2raw.drop([0,1,2,3])\n",
        "Y_a2.reset_index(inplace=True)\n",
        "Y_a2.drop(['index'],axis=1,inplace=True)\n",
        "Y_a2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "7j0HqnPSdL_1",
        "outputId": "eebe6a42-4471-4ced-e3b5-47fe7e5b8d3f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           lhx       lhy       lhz       rhx       rhy       rhz        hx  \\\n",
              "0     4.497225  5.598363  1.684676  6.932706  5.420004  1.648139  5.532781   \n",
              "1     4.504442  5.563369  1.682441  6.984883  5.338807  1.662477  5.535068   \n",
              "2     4.501790  5.587282  1.681250  6.936526  5.400179  1.650723  5.536529   \n",
              "3     4.481035  5.558424  1.678168  6.935569  5.403949  1.650177  5.536117   \n",
              "4     4.490471  5.547697  1.677370  6.954857  5.384894  1.654895  5.537160   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1255  3.766681  5.047060  1.599805  6.787716  4.922377  1.483261  5.494840   \n",
              "1256  3.772569  5.135340  1.607126  6.771120  4.998858  1.492831  5.457356   \n",
              "1257  3.781345  5.191569  1.616638  6.748940  5.098884  1.488763  5.463538   \n",
              "1258  3.794636  5.245894  1.628859  6.735619  5.142869  1.507751  5.469743   \n",
              "1259  3.815556  5.279714  1.638650  6.699938  5.184754  1.514433  5.480086   \n",
              "\n",
              "            hy        hz        sx        sy        sz       lwx       lwy  \\\n",
              "0     1.472957  1.781428  5.581297  4.110899  1.776406  4.550096  5.212202   \n",
              "1     1.473257  1.780948  5.581542  4.111409  1.776078  4.534203  5.175910   \n",
              "2     1.473684  1.780335  5.581291  4.111289  1.775740  4.530342  5.199273   \n",
              "3     1.472946  1.780279  5.581693  4.109772  1.775356  4.523950  5.174112   \n",
              "4     1.473327  1.779768  5.582080  4.108705  1.775060  4.521791  5.162915   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1255  1.408275  1.695259  5.391037  4.153896  1.700377  4.035254  4.780551   \n",
              "1256  1.410738  1.691791  5.375273  4.153625  1.699941  4.155283  5.046596   \n",
              "1257  1.409960  1.692598  5.366023  4.152654  1.699411  4.154757  5.052544   \n",
              "1258  1.409930  1.692958  5.356151  4.152353  1.699148  4.155412  5.076689   \n",
              "1259  1.410949  1.694152  5.343333  4.151536  1.698735  4.169959  5.114348   \n",
              "\n",
              "           lwz       rwx       rwy       rwz  timestamp       phase  \n",
              "0     1.688152  6.621651  5.184755  1.650331    5103827        Rest  \n",
              "1     1.689498  6.619938  5.200892  1.661059    5103859        Rest  \n",
              "2     1.687336  6.613071  5.181889  1.651599    5103893        Rest  \n",
              "3     1.688738  6.613035  5.184223  1.651119    5103916        Rest  \n",
              "4     1.688910  6.594951  5.234004  1.653260    5103947        Rest  \n",
              "...        ...       ...       ...       ...        ...         ...  \n",
              "1255  1.625402  6.644851  4.683230  1.522554    5155770  Retraction  \n",
              "1256  1.621549  6.672435  4.837710  1.516715    5155833  Retraction  \n",
              "1257  1.622160  6.684550  4.894862  1.529447    5155902  Retraction  \n",
              "1258  1.623406  6.632552  4.916888  1.539666    5155939  Retraction  \n",
              "1259  1.622405  6.615832  4.942080  1.543551    5155956  Retraction  \n",
              "\n",
              "[1260 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb59ac0f-38ee-4891-8be3-439bb92c74e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lhx</th>\n",
              "      <th>lhy</th>\n",
              "      <th>lhz</th>\n",
              "      <th>rhx</th>\n",
              "      <th>rhy</th>\n",
              "      <th>rhz</th>\n",
              "      <th>hx</th>\n",
              "      <th>hy</th>\n",
              "      <th>hz</th>\n",
              "      <th>sx</th>\n",
              "      <th>sy</th>\n",
              "      <th>sz</th>\n",
              "      <th>lwx</th>\n",
              "      <th>lwy</th>\n",
              "      <th>lwz</th>\n",
              "      <th>rwx</th>\n",
              "      <th>rwy</th>\n",
              "      <th>rwz</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.497225</td>\n",
              "      <td>5.598363</td>\n",
              "      <td>1.684676</td>\n",
              "      <td>6.932706</td>\n",
              "      <td>5.420004</td>\n",
              "      <td>1.648139</td>\n",
              "      <td>5.532781</td>\n",
              "      <td>1.472957</td>\n",
              "      <td>1.781428</td>\n",
              "      <td>5.581297</td>\n",
              "      <td>4.110899</td>\n",
              "      <td>1.776406</td>\n",
              "      <td>4.550096</td>\n",
              "      <td>5.212202</td>\n",
              "      <td>1.688152</td>\n",
              "      <td>6.621651</td>\n",
              "      <td>5.184755</td>\n",
              "      <td>1.650331</td>\n",
              "      <td>5103827</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.504442</td>\n",
              "      <td>5.563369</td>\n",
              "      <td>1.682441</td>\n",
              "      <td>6.984883</td>\n",
              "      <td>5.338807</td>\n",
              "      <td>1.662477</td>\n",
              "      <td>5.535068</td>\n",
              "      <td>1.473257</td>\n",
              "      <td>1.780948</td>\n",
              "      <td>5.581542</td>\n",
              "      <td>4.111409</td>\n",
              "      <td>1.776078</td>\n",
              "      <td>4.534203</td>\n",
              "      <td>5.175910</td>\n",
              "      <td>1.689498</td>\n",
              "      <td>6.619938</td>\n",
              "      <td>5.200892</td>\n",
              "      <td>1.661059</td>\n",
              "      <td>5103859</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.501790</td>\n",
              "      <td>5.587282</td>\n",
              "      <td>1.681250</td>\n",
              "      <td>6.936526</td>\n",
              "      <td>5.400179</td>\n",
              "      <td>1.650723</td>\n",
              "      <td>5.536529</td>\n",
              "      <td>1.473684</td>\n",
              "      <td>1.780335</td>\n",
              "      <td>5.581291</td>\n",
              "      <td>4.111289</td>\n",
              "      <td>1.775740</td>\n",
              "      <td>4.530342</td>\n",
              "      <td>5.199273</td>\n",
              "      <td>1.687336</td>\n",
              "      <td>6.613071</td>\n",
              "      <td>5.181889</td>\n",
              "      <td>1.651599</td>\n",
              "      <td>5103893</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.481035</td>\n",
              "      <td>5.558424</td>\n",
              "      <td>1.678168</td>\n",
              "      <td>6.935569</td>\n",
              "      <td>5.403949</td>\n",
              "      <td>1.650177</td>\n",
              "      <td>5.536117</td>\n",
              "      <td>1.472946</td>\n",
              "      <td>1.780279</td>\n",
              "      <td>5.581693</td>\n",
              "      <td>4.109772</td>\n",
              "      <td>1.775356</td>\n",
              "      <td>4.523950</td>\n",
              "      <td>5.174112</td>\n",
              "      <td>1.688738</td>\n",
              "      <td>6.613035</td>\n",
              "      <td>5.184223</td>\n",
              "      <td>1.651119</td>\n",
              "      <td>5103916</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.490471</td>\n",
              "      <td>5.547697</td>\n",
              "      <td>1.677370</td>\n",
              "      <td>6.954857</td>\n",
              "      <td>5.384894</td>\n",
              "      <td>1.654895</td>\n",
              "      <td>5.537160</td>\n",
              "      <td>1.473327</td>\n",
              "      <td>1.779768</td>\n",
              "      <td>5.582080</td>\n",
              "      <td>4.108705</td>\n",
              "      <td>1.775060</td>\n",
              "      <td>4.521791</td>\n",
              "      <td>5.162915</td>\n",
              "      <td>1.688910</td>\n",
              "      <td>6.594951</td>\n",
              "      <td>5.234004</td>\n",
              "      <td>1.653260</td>\n",
              "      <td>5103947</td>\n",
              "      <td>Rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>3.766681</td>\n",
              "      <td>5.047060</td>\n",
              "      <td>1.599805</td>\n",
              "      <td>6.787716</td>\n",
              "      <td>4.922377</td>\n",
              "      <td>1.483261</td>\n",
              "      <td>5.494840</td>\n",
              "      <td>1.408275</td>\n",
              "      <td>1.695259</td>\n",
              "      <td>5.391037</td>\n",
              "      <td>4.153896</td>\n",
              "      <td>1.700377</td>\n",
              "      <td>4.035254</td>\n",
              "      <td>4.780551</td>\n",
              "      <td>1.625402</td>\n",
              "      <td>6.644851</td>\n",
              "      <td>4.683230</td>\n",
              "      <td>1.522554</td>\n",
              "      <td>5155770</td>\n",
              "      <td>Retraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>3.772569</td>\n",
              "      <td>5.135340</td>\n",
              "      <td>1.607126</td>\n",
              "      <td>6.771120</td>\n",
              "      <td>4.998858</td>\n",
              "      <td>1.492831</td>\n",
              "      <td>5.457356</td>\n",
              "      <td>1.410738</td>\n",
              "      <td>1.691791</td>\n",
              "      <td>5.375273</td>\n",
              "      <td>4.153625</td>\n",
              "      <td>1.699941</td>\n",
              "      <td>4.155283</td>\n",
              "      <td>5.046596</td>\n",
              "      <td>1.621549</td>\n",
              "      <td>6.672435</td>\n",
              "      <td>4.837710</td>\n",
              "      <td>1.516715</td>\n",
              "      <td>5155833</td>\n",
              "      <td>Retraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>3.781345</td>\n",
              "      <td>5.191569</td>\n",
              "      <td>1.616638</td>\n",
              "      <td>6.748940</td>\n",
              "      <td>5.098884</td>\n",
              "      <td>1.488763</td>\n",
              "      <td>5.463538</td>\n",
              "      <td>1.409960</td>\n",
              "      <td>1.692598</td>\n",
              "      <td>5.366023</td>\n",
              "      <td>4.152654</td>\n",
              "      <td>1.699411</td>\n",
              "      <td>4.154757</td>\n",
              "      <td>5.052544</td>\n",
              "      <td>1.622160</td>\n",
              "      <td>6.684550</td>\n",
              "      <td>4.894862</td>\n",
              "      <td>1.529447</td>\n",
              "      <td>5155902</td>\n",
              "      <td>Retraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>3.794636</td>\n",
              "      <td>5.245894</td>\n",
              "      <td>1.628859</td>\n",
              "      <td>6.735619</td>\n",
              "      <td>5.142869</td>\n",
              "      <td>1.507751</td>\n",
              "      <td>5.469743</td>\n",
              "      <td>1.409930</td>\n",
              "      <td>1.692958</td>\n",
              "      <td>5.356151</td>\n",
              "      <td>4.152353</td>\n",
              "      <td>1.699148</td>\n",
              "      <td>4.155412</td>\n",
              "      <td>5.076689</td>\n",
              "      <td>1.623406</td>\n",
              "      <td>6.632552</td>\n",
              "      <td>4.916888</td>\n",
              "      <td>1.539666</td>\n",
              "      <td>5155939</td>\n",
              "      <td>Retraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>3.815556</td>\n",
              "      <td>5.279714</td>\n",
              "      <td>1.638650</td>\n",
              "      <td>6.699938</td>\n",
              "      <td>5.184754</td>\n",
              "      <td>1.514433</td>\n",
              "      <td>5.480086</td>\n",
              "      <td>1.410949</td>\n",
              "      <td>1.694152</td>\n",
              "      <td>5.343333</td>\n",
              "      <td>4.151536</td>\n",
              "      <td>1.698735</td>\n",
              "      <td>4.169959</td>\n",
              "      <td>5.114348</td>\n",
              "      <td>1.622405</td>\n",
              "      <td>6.615832</td>\n",
              "      <td>4.942080</td>\n",
              "      <td>1.543551</td>\n",
              "      <td>5155956</td>\n",
              "      <td>Retraction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1260 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb59ac0f-38ee-4891-8be3-439bb92c74e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb59ac0f-38ee-4891-8be3-439bb92c74e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb59ac0f-38ee-4891-8be3-439bb92c74e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acd7ee2e-e3fd-4b70-b8e4-25f25bb12c65\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acd7ee2e-e3fd-4b70-b8e4-25f25bb12c65')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acd7ee2e-e3fd-4b70-b8e4-25f25bb12c65 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1=list(range(0,5))\n",
        "Y_a2['phase'].replace(Y_a2['phase'].unique(),list1,inplace=True)\n",
        "y_a2=Y_a2['phase'].values\n",
        "\n",
        "y_a2_nophase=Y_a2.drop(['phase'],axis=1)\n",
        "xa2test=pd.concat([test,y_a2_nophase],axis=1)\n",
        "xa2test\n",
        "print(y_a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmhA-NzDdHo0",
        "outputId": "d61aa073-e8c1-46aa-c936-293ca81071c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lgbm_a2=lgbm.predict(xa2test)"
      ],
      "metadata": {
        "id": "dWIHqNAvfJH4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "G19SoNqwaP2g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_pred_lgbm_a2,y_a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Ti4_f1fOdg",
        "outputId": "0429dc66-511c-46c8-ebec-82580947f10f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6753968253968254"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lgbm_a2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvemRLtGf_h0",
        "outputId": "dfdc029f-f006-4002-fcc9-9f8627b21e53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1= ['D','P','S','H','R']\n",
        "final=[]\n",
        "for i in y_pred_lgbm_a2:\n",
        "  final.append(list[i])\n"
      ],
      "metadata": {
        "id": "6FWw6GRUSwuK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID=[]\n",
        "for i in range(1260):\n",
        "  ID.append(i+1)\n",
        "print(ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCfoKs8xUwqR",
        "outputId": "bb6bff50-7504-43ca-aabd-a8565fc168fa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission = pd.DataFrame({'ID': ID, 'Phase': final})\n",
        "my_submission.to_csv('/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/submission_lgbm.csv', index=False)\n"
      ],
      "metadata": {
        "id": "_LLzDj0wUNrj"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "BbRewsePXEiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import cv"
      ],
      "metadata": {
        "id": "4LHiV6iM6byg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)\n"
      ],
      "metadata": {
        "id": "7Gizx_mONMmn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5],\n",
        "        'learning_rate':[0.1,0.01,0.02,1]\n",
        "        }"
      ],
      "metadata": {
        "id": "hD78jJscLDQ3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model=XGBClassifier(n_estimators=400,nthread=1,objective='multi:softmax')\n"
      ],
      "metadata": {
        "id": "cb_3PVqTPA_I"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "PMX7ePXBK8RD",
        "outputId": "82409f99-1741-4659-e601-233fc6aa13e5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=400, n_jobs=None, nthread=1, num_parallel_tree=None,\n",
              "              objective='multi:softmax', ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=400, n_jobs=None, nthread=1, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=400, n_jobs=None, nthread=1, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb_a2=xgb_model.predict(xa2test)\n"
      ],
      "metadata": {
        "id": "wQ9NjC6q7Lj_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_pred_xgb_a2,y_a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dDJw9AU7nXs",
        "outputId": "02b6208b-255a-4d3b-ccb1-ed78f33026e3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6952380952380952"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list2= ['D','P','S','H','R']\n",
        "final=[]\n",
        "for i in y_pred_xgb_a2:\n",
        "  final.append(list[i])\n"
      ],
      "metadata": {
        "id": "MsysV7bIYvwU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID=[]\n",
        "for i in range(1260):\n",
        "  ID.append(i+1)\n",
        "print(ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5C-3gMqYx38",
        "outputId": "7b9cd305-723f-4b9b-a5b9-5ec4996bb05a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_xgboost = pd.DataFrame({'ID': ID, 'Phase': final})\n",
        "my_submission_xgboost.to_csv('/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/submission_xgboost.csv', index=False)\n"
      ],
      "metadata": {
        "id": "LTZHXRLdY8sd"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "9C5MT8mYX3GP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds = 5\n",
        "param_comb = 5\n",
        "\n",
        "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
        "\n",
        "randomsearch = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X,y), verbose=3, random_state=1001 )\n",
        "randomsearch.fit(X, y)\n"
      ],
      "metadata": {
        "id": "huEFEA_1XvQ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "a24767ab-1467-441c-89d5-331074980a0b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f07ad022960>,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type...\n",
              "                                           monotone_constraints=None,\n",
              "                                           n_estimators=400, n_jobs=None,\n",
              "                                           nthread=1, num_parallel_tree=None,\n",
              "                                           objective='multi:softmax', ...),\n",
              "                   n_iter=5, n_jobs=4,\n",
              "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
              "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
              "                                        'learning_rate': [0.1, 0.01, 0.02, 1],\n",
              "                                        'max_depth': [3, 4, 5],\n",
              "                                        'min_child_weight': [1, 5, 10],\n",
              "                                        'subsample': [0.6, 0.8, 1.0]},\n",
              "                   random_state=1001, scoring='roc_auc', verbose=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x7f07ad022960&gt;,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type...\n",
              "                                           monotone_constraints=None,\n",
              "                                           n_estimators=400, n_jobs=None,\n",
              "                                           nthread=1, num_parallel_tree=None,\n",
              "                                           objective=&#x27;multi:softmax&#x27;, ...),\n",
              "                   n_iter=5, n_jobs=4,\n",
              "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
              "                                        &#x27;gamma&#x27;: [0.5, 1, 1.5, 2, 5],\n",
              "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 0.02, 1],\n",
              "                                        &#x27;max_depth&#x27;: [3, 4, 5],\n",
              "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
              "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
              "                   random_state=1001, scoring=&#x27;roc_auc&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=&lt;generator object _BaseKFold.split at 0x7f07ad022960&gt;,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type...\n",
              "                                           monotone_constraints=None,\n",
              "                                           n_estimators=400, n_jobs=None,\n",
              "                                           nthread=1, num_parallel_tree=None,\n",
              "                                           objective=&#x27;multi:softmax&#x27;, ...),\n",
              "                   n_iter=5, n_jobs=4,\n",
              "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
              "                                        &#x27;gamma&#x27;: [0.5, 1, 1.5, 2, 5],\n",
              "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 0.02, 1],\n",
              "                                        &#x27;max_depth&#x27;: [3, 4, 5],\n",
              "                                        &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
              "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
              "                   random_state=1001, scoring=&#x27;roc_auc&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=400, n_jobs=None, nthread=1, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=400, n_jobs=None, nthread=1, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n All results:')\n",
        "print(randomsearch.cv_results_)\n",
        "print('\\n Best estimator:')\n",
        "print(randomsearch.best_estimator_)\n",
        "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
        "print(randomsearch.best_score_ * 2 - 1)\n",
        "print('\\n Best hyperparameters:')\n",
        "print(randomsearch.best_params_)\n",
        "results = pd.DataFrame(randomsearch.cv_results_)\n",
        "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
      ],
      "metadata": {
        "id": "YkegXZwm22_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a4404f-7cd8-4176-93c9-a57bc2526273"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " All results:\n",
            "{'mean_fit_time': array([197.39904776, 227.97758846, 258.94723792, 139.75200572,\n",
            "       244.76948318]), 'std_fit_time': array([ 4.87418783,  2.79416663,  2.5347546 ,  1.46544292, 58.12875989]), 'mean_score_time': array([0.00361195, 0.00266466, 0.00352955, 0.00089574, 0.00095153]), 'std_score_time': array([0.00391645, 0.00138396, 0.00286   , 0.00091305, 0.00095201]), 'param_subsample': masked_array(data=[0.8, 1.0, 0.8, 0.8, 1.0],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_min_child_weight': masked_array(data=[5, 5, 10, 10, 1],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_max_depth': masked_array(data=[4, 4, 5, 4, 4],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_learning_rate': masked_array(data=[0.1, 0.01, 0.1, 0.02, 0.01],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_gamma': masked_array(data=[2, 2, 1, 1.5, 5],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.8, 0.8, 1.0, 0.6, 1.0],\n",
            "             mask=[False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.1, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 4, 'learning_rate': 0.02, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 1.0}], 'split0_test_score': array([nan, nan, nan, nan, nan]), 'split1_test_score': array([nan, nan, nan, nan, nan]), 'split2_test_score': array([nan, nan, nan, nan, nan]), 'split3_test_score': array([nan, nan, nan, nan, nan]), 'split4_test_score': array([nan, nan, nan, nan, nan]), 'mean_test_score': array([nan, nan, nan, nan, nan]), 'std_test_score': array([nan, nan, nan, nan, nan]), 'rank_test_score': array([1, 1, 1, 1, 1], dtype=int32)}\n",
            "\n",
            " Best estimator:\n",
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=2, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=400, n_jobs=None, nthread=1, num_parallel_tree=None,\n",
            "              objective='multi:softmax', ...)\n",
            "\n",
            " Best normalized gini score for 5-fold search with 5 parameter combinations:\n",
            "nan\n",
            "\n",
            " Best hyperparameters:\n",
            "{'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.1, 'gamma': 2, 'colsample_bytree': 0.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = randomsearch.best_estimator_"
      ],
      "metadata": {
        "id": "1smwxidb4Z2H"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_a2_pred_rs=best_model.predict(xa2test)"
      ],
      "metadata": {
        "id": "JF4VHNBfT3eZ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_a2_pred_rs,y_a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcVBGk2mWINc",
        "outputId": "0378a583-9cdf-4a48-b90b-cee4b842d31c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6682539682539682"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list= ['D','P','S','H','R']\n",
        "final=[]\n",
        "for i in y_a2_pred_rs:\n",
        "  final.append(list[i])\n"
      ],
      "metadata": {
        "id": "GCAlfjHXZXNU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID=[]\n",
        "for i in range(1260):\n",
        "  ID.append(i+1)\n",
        "print(ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZxtHIykZlcv",
        "outputId": "c8c14832-418e-460c-c938-dd1da57c43f8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_rs = pd.DataFrame({'ID': ID, 'Phase': final})\n",
        "my_submission_rs.to_csv('/content/drive/MyDrive/kaggle/dsg-challenge-1-supervised-learning/submission_rs.csv', index=False)\n"
      ],
      "metadata": {
        "id": "5i6cj2-wZn12"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}