{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af85fdf1-8040-4aa6-bbd8-b698dc4007fa",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "For each of parts, indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer using concepts covered during the lecture and try to hit upon certain key-terms. Also, discuss the bias and variance tradeoff in each scenario.\n",
    "a. The sample size n is extremely large, and the number of predictors p is small.\n",
    "b. The number of predictors p is extremely large, and the number of observations n is small.\n",
    "c. The relationship between the predictors and response is highly non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d671e-2367-4cb1-9ec1-b9ffe43ee21a",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "a.\n",
    "Moderately flexible methods would work better here since less number of input features means too much model complexity is not required. High complexity methods would cause extremely low bias (since data is sufficient) and high variance (since extra parameters will be used to memorize data). And low flexibility would perform poorly as data might have slightly complex patterns, causing high bias and low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052c856-ba5e-4663-9cca-5cb9e7b3ca99",
   "metadata": {},
   "source": [
    "b.\n",
    "Inflexible methods would work better here high complexity models would definitely cause overfitting due to low number of samples. The high number of features would increase the scope of \"memorization\" as the model might infer patterns that do not exist. Non parametric methods would also be better since with low amount of data it is difficult to make assumptions about its distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee7fbf5-bc86-4ffa-865c-2add194c3261",
   "metadata": {},
   "source": [
    "c.\n",
    "Depends on the choice of model, one can use low complexity models even if they're non linear (like SVMs). Linear data -> low complexity but non linear -/> high complexity. So the answer depends on the amount of data available and the model in question. ex. if data is highly non linear but number of data points is also low (so youd want to keep the number of parameters low) you could use a slightly deep but narrow neural network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
